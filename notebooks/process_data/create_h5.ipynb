{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all fasta into one big .hdf5 file\n",
    "@author Harald Ringbauer, March 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current machine: compute-e-16-237.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/covid19_data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n",
    "from shutil import which\n",
    "import os\n",
    "import re as re\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "socket_name = socket.gethostname()\n",
    "print(f\"Current machine: {socket_name}\")\n",
    "if socket_name == \"DESKTOP-5RJD9NC\":\n",
    "    path = \"/gitProjects/covid19_data\"   # The Path on Harald's machine\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/covid19_data/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "### Check whether required bins are available\n",
    "req_bins = [\"mafft\"] \n",
    "for b in req_bins:\n",
    "    s = which(b)\n",
    "    if not s:\n",
    "        print(f\"Make sure to install {b} and have in path. I cannot find it!\")\n",
    "        \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd())\n",
    "\n",
    "sys.path.append(\"./python3/\")\n",
    "from manipulate_fasta import fasta_iter_raw, fasta_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Key Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aligned_seq(fasta_path, align_id=\"Wuhan-Hu-1\"):\n",
    "    \"\"\"Load Aligned Sequence fasta.\n",
    "    Check against align_id and lgth.\n",
    "    Return String\"\"\"\n",
    "    fiter = fasta_iter(fasta_path)\n",
    "    iid_re, _ = next(fiter)\n",
    "    \n",
    "    if len(align_id)>0:\n",
    "        if not (align_id in iid_re):\n",
    "            raise RuntimeWarning(f\"Reference ID {align_id} does not match {iid_re}\")\n",
    "    iid, seq = next(fiter)  # Get the Meat\n",
    "    return iid, seq\n",
    "\n",
    "def combine_fasta_alignments(paths, align_id=\"Wuhan-Hu-1\"):\n",
    "    \"\"\"Load, and combine all the paths \"\"\"\n",
    "    n = len(paths)\n",
    "    \n",
    "    _, seq = load_aligned_seq(paths[0], align_id=align_id)\n",
    "    k = len(seq)\n",
    "    \n",
    "    seqs = np.empty((n,k), dtype=\"|S1\")  # Create place holder for all sequences\n",
    "    iids = np.empty(n, dtype=\"str\") # Place holder for the iids\n",
    "    \n",
    "    for i, path in enumerate(paths):\n",
    "        iid, seq = load_aligned_seq(path, align_id=align_id)\n",
    "        iids[i], seqs[i,:] = iid, seq # Typecast into list so assignment works\n",
    "    return iids, seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run and Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1746 Sequences from ./output/single_seq_aligned.tsv\n"
     ]
    }
   ],
   "source": [
    "aligned_path_fasta = \"./output/single_seq_aligned.tsv\"\n",
    "\n",
    "df = pd.read_csv(aligned_path_fasta, sep=\"\\t\")\n",
    "df = df[df[\"include\"]==True].copy()\n",
    "print(f\"Loaded {len(df)} Sequences from {aligned_path_fasta}\")\n",
    "\n",
    "### Manually filling in (next iteration has it automatic)\n",
    "df[\"aligned_path\"] = \"./output/singleseq_aligned/\" + df[\"iid_clean\"] + \".fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = df[\"aligned_path\"][:5]\n",
    "\n",
    "iids, seqs = combine_fasta_alignments(paths, align_id=\"Wuhan-Hu-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fasta = \"./output/singleseq_aligned/hCoV-19.Beijing.105.2020.EPI_ISL_413518.2020-01-26.fasta\"\n",
    "#fiter = fasta_iter(path_fasta)\n",
    "#iids = np.array([ff[0] for ff in fiter])\n",
    "#next(fiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MN908947.3 Severe acute respiratory syndrome coronavirus 2 isolate Wuhan-Hu-1, complete genome',\n",
       "       'hCoV-19/Beijing/105/2020|EPI_ISL_413518|2020-01-26'], dtype='<U94')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fasta = \"./output/singleseq_aligned/hCoV-19.Beijing.105.2020.EPI_ISL_413518.2020-01-26.fasta\"\n",
    "#fiter = fasta_iter(path_fasta)\n",
    "load_aligned_seq(path_fasta, align_id=\"Wuhan-Hu-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"iid\":[\"a\", \"b\", \"c\"]})\n",
    "df[\"b\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(row[\"iid\"])\n",
    "    row[\"iid\"] = \"d\"\n",
    "    row[\"b\"] = \"e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'n', b'n', b'n', ..., b'n', b'n', b'n'],\n",
       "       [b'n', b'n', b'n', ..., b'n', b'n', b'n'],\n",
       "       [b'n', b'n', b'n', ..., b'n', b'n', b'n'],\n",
       "       [b'n', b'n', b'n', ..., b'n', b'n', b'n'],\n",
       "       [b'n', b'n', b'n', ..., b'n', b'n', b'n']], dtype='|S1')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
