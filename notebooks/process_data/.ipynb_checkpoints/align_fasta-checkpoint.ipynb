{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align Fasta to Reference Fasta\n",
    "Works in two steps:\n",
    "1) Split up the big dataframe (takes 1 min per 5000 seqs)\n",
    "\n",
    "2) Align 1by1. (takes 10 min per 5000 seqs) [only new ones??]\n",
    "\n",
    "To keep track what is already aligned, a summary dataframe can be merged in, \n",
    "that keeps track where the indivdiual output files should be.\n",
    "This is some iteration of 'output/single_seq_alignedX.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current machine: compute-a-16-106.o2.rc.hms.harvard.edu\n",
      "HMS Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/covid19_data\n",
      "CPU Count: 32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n",
    "from shutil import which\n",
    "import os\n",
    "import re as re\n",
    "import h5py  # Python Package to do the HDF5.\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "socket_name = socket.gethostname()\n",
    "print(f\"Current machine: {socket_name}\")\n",
    "if socket_name == \"DESKTOP-5RJD9NC\":\n",
    "    path = \"/gitProjects/covid19_data\"   # The Path on Harald's machine\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HMS Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/covid19_data/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "### Check whether required bins are available\n",
    "req_bins = [\"mafft\"] \n",
    "for b in req_bins:\n",
    "    s = which(b)\n",
    "    if not s:\n",
    "        print(f\"Make sure to install {b} and have in path. I cannot find it!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Fasta File (remove is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fasta(sample_line, seq_lines, savepath=\"\", output=True):\n",
    "    \"\"\"Write a single Fasta file.\n",
    "    sample_li./output/e of the Sample to write\n",
    "    seq_lines: Genotype Sequences to write\n",
    "    savepath: Where to write Fasta File to\n",
    "    \"\"\"\n",
    "    f1 = open(savepath, \"w\")\n",
    "    f1.write(sample_line)  # Write the new line\n",
    "    for line in seq_lines:\n",
    "        f1.write(line)\n",
    "    f1.close()\n",
    "    if output:\n",
    "        print(f\"Saved fasta to {savepath}\")\n",
    "    \n",
    "def fasta_iter_raw(fasta_name):\n",
    "    \"\"\"\n",
    "    Return iterator for fasta\n",
    "    \"\"\"\n",
    "    fh = open(fasta_name)\n",
    "    # ditch the boolean (x[0]) and just keep the header or sequence since\n",
    "    # we know they alternate.\n",
    "    faiter = (x[1] for x in groupby(fh, lambda line: line[0] == \">\"))\n",
    "    \n",
    "    for header in faiter:\n",
    "        # drop the \">\"\n",
    "        headerStr = header.__next__()   #[1:].strip()\n",
    "        # join all sequence lines to one.\n",
    "        seq = \"\".join(s for s in faiter.__next__())  # .strip()\n",
    "        yield (headerStr, seq) \n",
    "        \n",
    "def fasta_iter(fasta_name):\n",
    "    \"\"\"\n",
    "    Return iterator for fasta\n",
    "    \"\"\"\n",
    "    \"first open the file outside \"\n",
    "    fh = open(fasta_name)\n",
    "    # ditch the boolean (x[0]) and just keep the header or sequence since\n",
    "    # we know they alternate.\n",
    "    faiter = (x[1] for x in groupby(fh, lambda line: line[0] == \">\"))\n",
    "   \n",
    "    for header in faiter:\n",
    "        # drop the \">\"\n",
    "        headerStr = header.__next__()[1:].strip()\n",
    "        # join all sequence lines to one.\n",
    "        seq = \"\".join(s.strip() for s in faiter.__next__())\n",
    "        yield (headerStr, seq) \n",
    "        \n",
    "def clean_seq_line(seq_line, replace_char=r'[^ACGTN\\n\\r]',\n",
    "                   with_char=\"N\"):\n",
    "    \"\"\"Clean seq_line String.\n",
    "    Return updated string\"\"\"\n",
    "    seq_line = seq_line.upper()   # Make Upper Case\n",
    "    seq_line = re.sub(replace_char, with_char, seq_line)\n",
    "    return seq_line\n",
    "\n",
    "def include_samples(sample_seq, min_cov_bs):\n",
    "    \"\"\"Quick check whether to include sample.\n",
    "    min_cov_bs: Minimum Number of covered Bases\n",
    "    return include status, nr covered bases\"\"\"\n",
    "    lgth = len(sample_seq) - sample_seq.count('\\n') - sample_seq.count(\"N\")\n",
    "    if lgth >= min_cov_bs:\n",
    "        include = True\n",
    "    else:\n",
    "        include = False\n",
    "    return include, lgth\n",
    "        \n",
    "def split_fasta(fasta_name, path_out=\"./output/singleseq/\", \n",
    "                iids=[], clean=True, min_cov_bs=20000, \n",
    "                overwrite=False, output=True):\n",
    "    \"\"\"\n",
    "    Splits up samples from fasta if IID string contains\n",
    "    clean: Whether to clean string (make everything upper-case \n",
    "    and substitute with N)\n",
    "    overwrite: Whether to overwrite fasta\n",
    "    min_cov_bs: How many bases covered at least once\n",
    "    Return list of samples that have been run\n",
    "    \"\"\"\n",
    "    fiter = fasta_iter_raw(fasta_name)\n",
    "    iids_org, iids_prcsd = [], []\n",
    "    cvg, icld = [], []\n",
    "    new=0  # Counter for newly written files\n",
    "    existing=0 # Counter for exsiting files\n",
    "    \n",
    "    for j, (sample_line, seq_line) in enumerate(fiter):\n",
    "        if j%1000 == 0:\n",
    "            print(f\"Running individual # {j}\")\n",
    "        j+=1\n",
    "        sample = sample_line[1:].strip()\n",
    "        if sample in iids:\n",
    "            if output:\n",
    "                print(f\"Matched: {sample}\")\n",
    "            sample1 = re.sub(\"[\\|\\/]\", \".\", sample)\n",
    "            sample1 = re.sub(\"\\s\", \"_\", sample1) # Remplace White Spaces\n",
    "            \n",
    "            if clean:\n",
    "                seq_line = clean_seq_line(seq_line)\n",
    "            include, lgth = include_samples(seq_line, min_cov_bs=min_cov_bs)\n",
    "            \n",
    "            ### Append Statistics\n",
    "            iids_org.append(sample)\n",
    "            iids_prcsd.append(sample1)\n",
    "            cvg.append(lgth)\n",
    "            icld.append(include)\n",
    "            \n",
    "            fasta_name_out = os.path.join(path_out, sample1 + \".fasta\")\n",
    "            exist = os.path.exists(fasta_name_out) # Check whether already there\n",
    "            existing+= exist  # Add to counter\n",
    "            \n",
    "            if overwrite:\n",
    "                exist=False # Overwrite anyways\n",
    "            \n",
    "            if include and (not exist):\n",
    "                write_fasta(sample_line, seq_line, fasta_name_out, output=output)\n",
    "                new+=1\n",
    "                \n",
    "    print(f\"Sucessfully written: n={new} fastas into {path_out}\")\n",
    "    print(f\"Paths already existing: n={existing}\")\n",
    "                \n",
    "    ### Make a Summary Dataframe\n",
    "    df = pd.DataFrame({\"iid\":iids_org, \"iid_clean\":iids_prcsd, \n",
    "                        \"cov\":cvg,  \"include\":icld, \"aligned_path\": \"\"})\n",
    "    return df\n",
    "                  \n",
    "def clean_fasta(fasta_name, fasta_name_out):\n",
    "    \"\"\"\n",
    "    Remove invalid characters in sequences\n",
    "    \"\"\"\n",
    "    \"first open the file outside \"\n",
    "    f = open(fasta_name)\n",
    "    f1 = open(fasta_name_out, \"w\")\n",
    "    n=0\n",
    "    \n",
    "    for line in f:\n",
    "        if line[0]==\">\":\n",
    "            n+=1\n",
    "        else:   # If Genome Data replace i\n",
    "            line = line.replace(\"i\", \"N\")\n",
    "        f1.write(line)  # Write the new line\n",
    "    f.close()\n",
    "    f1.close()\n",
    "    print(f\"Successfully Modified {n} fastas\")\n",
    "    print(f\"Saved to {clean_fasta_path}\")\n",
    "    \n",
    "def align_mafft(in_path, out_path, ref_path=\"./data/reference/wuhan-hu-1.fasta\", \n",
    "                thread=10, output=True):\n",
    "    \"\"\"Align in_path against ref_path using MAFFT.\n",
    "    Save in out_path\"\"\"\n",
    "    if output:\n",
    "        !mafft --out $out_path --add $in_path --thread $thread --keeplength $ref_path\n",
    "    else: \n",
    "        !mafft --out $out_path --add $in_path --thread $thread --quiet --keeplength $ref_path \n",
    "    \n",
    "def align_mafft_multiple(df, \n",
    "                         in_folder = \"./output/singleseq/\",\n",
    "                         out_folder=\"./output/singleseq_aligned/\",\n",
    "                         ref_path = \"./data/reference/wuhan-hu-1.fasta\",\n",
    "                         save_path_df = \"\", threads=10, output=False, overwrite=False,\n",
    "                         iid_col=\"iid_clean\", align_col = \"aligned_path\", icl_col=\"include\",\n",
    "                         ):\n",
    "    \"\"\"Align all sequences not yet aligned\n",
    "    df: Dataframe with sample iids\n",
    "    out_folder: Where to save \n",
    "    overwrite: Whether to overwrite existing output\"\"\"\n",
    "    \n",
    "    if align_col not in df:\n",
    "        df[align_col] = \"\"\n",
    "    \n",
    "    print(f\"Total alignment rows: {len(df)}\")\n",
    "    j=0\n",
    "    new=0 # Counter Varaible for new alignments\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if j%1000==0 and output:\n",
    "            print(f\"Doing row {j}\")\n",
    "        j+=1\n",
    "        iid = row[iid_col]\n",
    "        align_path = row[align_col]\n",
    "        align_path1 = os.path.join(out_folder, iid + \".fasta\")\n",
    "        icld = row[icl_col]  # Variable whether to include that sequence\n",
    "        \n",
    "        if (align_path != align_path1) and icld:  # Works also if np.nan\n",
    "            if os.path.exists(align_path1):\n",
    "                df.at[index, align_col] = align_path1 # Fill in just in cases\n",
    "                if not overwrite:\n",
    "                    continue\n",
    "            new+=1\n",
    "            in_path = os.path.join(in_folder, iid + \".fasta\")\n",
    "            align_mafft(in_path, out_path=align_path1, \n",
    "                        ref_path=ref_path, thread=threads, output=output) \n",
    "                \n",
    "    print(f\"Successfully newly aligned n={new} sequences.\")\n",
    "    if len(save_path_df)>0:\n",
    "        df.to_csv(save_path_df, sep=\"\\t\", index=False)\n",
    "        print(f\"Saved Summary Dataframe n={len(df)} to {save_path_df}\")\n",
    "        \n",
    "    \n",
    "        \n",
    "def merge_new_existing_df(path_new= \"./output/single_seq_split.tsv\", \n",
    "                          path_existing= \"output/single_seq_aligned.tsv\", \n",
    "                          savepath = \"same\",\n",
    "                          align_col = \"aligned_path\"):\n",
    "    \"\"\"Merge New and Existing Dataframe. Return the merged one\"\"\"\n",
    "    if savepath==\"same\":\n",
    "        savepath = path_existing\n",
    "\n",
    "    df1 = pd.read_csv(path_new, sep=\"\\t\") \n",
    "    df1[align_col] = \"\"\n",
    "    print(f\"Loaded {len(df1)} sequences to newly algin\")\n",
    "    df2 = pd.read_csv(path_existing, sep=\"\\t\")\n",
    "    print(f\"Loaded {len(df2)} sequences already aligned\")\n",
    "    ### Add the alginment to the new one:\n",
    "    \n",
    "    assert((df1.columns ==df2.columns).all())\n",
    "\n",
    "    df_merge = pd.concat([df2,df1]) # put existing ones first\n",
    "    df_merge = df_merge.drop_duplicates(subset=\"iid_clean\", keep=\"first\").reset_index(drop=True)\n",
    "    print(f\"combined to  {len(df_merge)} Unique clean IDs\")\n",
    "    ### Also drop eid duplicates\n",
    "    df_merge[\"iid\"] = df_merge[\"iid\"].str.replace(\"/\", \"|\")\n",
    "    ids = df_merge[\"iid\"].str.split(\"|\").str[1] # Parse out the unique IDs\n",
    "    \n",
    "    idx = ids.duplicated()  # Flags all duplicates\n",
    "    df_merge = df_merge[~idx].reset_index(drop=True)\n",
    "    print(f\"Filtered to  {len(df_merge)} Unique Sample IDs\")\n",
    "\n",
    "    if len(savepath)>0:\n",
    "        df_merge.to_csv(savepath, sep=\"\\t\", index=False)\n",
    "        print(f\"Saved New full Dataframe (n={len(df_merge)}) to {savepath}\")\n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the Multi FASTA into single FASTAs\n",
    "The downloaded files have at least 29k sequences\n",
    "(box checked at gisaid)\n",
    "\n",
    "takes 1 min per 5000 seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention: At some point the gisaid fastat had the first line blank\n",
    "Please manually remove it for them using\n",
    "\n",
    "tail -n +2 ./gisaid_hcov-19_2020_04_29_23.fasta > gisaid_hcov-19_2020_04_29_23_mod.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded n=166919 IIDs\n",
      "Splitting up fastas...\n",
      "Running individual # 0\n",
      "Running individual # 1000\n",
      "Running individual # 2000\n",
      "Running individual # 3000\n",
      "Running individual # 4000\n",
      "Running individual # 5000\n",
      "Running individual # 6000\n",
      "Running individual # 7000\n",
      "Running individual # 8000\n",
      "Running individual # 9000\n",
      "Running individual # 10000\n",
      "Running individual # 11000\n",
      "Running individual # 12000\n",
      "Running individual # 13000\n",
      "Running individual # 14000\n",
      "Running individual # 15000\n",
      "Running individual # 16000\n",
      "Running individual # 17000\n",
      "Running individual # 18000\n",
      "Running individual # 19000\n",
      "Running individual # 20000\n",
      "Running individual # 21000\n",
      "Running individual # 22000\n",
      "Running individual # 23000\n",
      "Running individual # 24000\n",
      "Running individual # 25000\n",
      "Running individual # 26000\n",
      "Running individual # 27000\n",
      "Running individual # 28000\n",
      "Running individual # 29000\n",
      "Running individual # 30000\n",
      "Running individual # 31000\n",
      "Running individual # 32000\n",
      "Running individual # 33000\n",
      "Running individual # 34000\n",
      "Running individual # 35000\n",
      "Running individual # 36000\n",
      "Running individual # 37000\n",
      "Running individual # 38000\n",
      "Running individual # 39000\n",
      "Running individual # 40000\n",
      "Running individual # 41000\n",
      "Running individual # 42000\n",
      "Running individual # 43000\n",
      "Running individual # 44000\n",
      "Running individual # 45000\n",
      "Running individual # 46000\n",
      "Running individual # 47000\n",
      "Running individual # 48000\n",
      "Running individual # 49000\n",
      "Running individual # 50000\n",
      "Running individual # 51000\n",
      "Running individual # 52000\n",
      "Running individual # 53000\n",
      "Running individual # 54000\n",
      "Running individual # 55000\n",
      "Running individual # 56000\n",
      "Running individual # 57000\n",
      "Running individual # 58000\n",
      "Running individual # 59000\n",
      "Running individual # 60000\n",
      "Running individual # 61000\n",
      "Running individual # 62000\n",
      "Running individual # 63000\n",
      "Running individual # 64000\n",
      "Running individual # 65000\n",
      "Running individual # 66000\n",
      "Running individual # 67000\n",
      "Running individual # 68000\n",
      "Running individual # 69000\n",
      "Running individual # 70000\n",
      "Running individual # 71000\n",
      "Running individual # 72000\n",
      "Running individual # 73000\n",
      "Running individual # 74000\n",
      "Running individual # 75000\n",
      "Running individual # 76000\n",
      "Running individual # 77000\n",
      "Running individual # 78000\n",
      "Running individual # 79000\n",
      "Running individual # 80000\n",
      "Running individual # 81000\n",
      "Running individual # 82000\n",
      "Running individual # 83000\n",
      "Running individual # 84000\n",
      "Running individual # 85000\n",
      "Running individual # 86000\n",
      "Running individual # 87000\n",
      "Running individual # 88000\n",
      "Running individual # 89000\n",
      "Running individual # 90000\n",
      "Running individual # 91000\n",
      "Running individual # 92000\n",
      "Running individual # 93000\n",
      "Running individual # 94000\n",
      "Running individual # 95000\n",
      "Running individual # 96000\n",
      "Running individual # 97000\n",
      "Running individual # 98000\n",
      "Running individual # 99000\n",
      "Running individual # 100000\n",
      "Running individual # 101000\n",
      "Running individual # 102000\n",
      "Running individual # 103000\n",
      "Running individual # 104000\n",
      "Running individual # 105000\n",
      "Running individual # 106000\n",
      "Running individual # 107000\n",
      "Running individual # 108000\n",
      "Running individual # 109000\n",
      "Running individual # 110000\n",
      "Running individual # 111000\n",
      "Running individual # 112000\n",
      "Running individual # 113000\n",
      "Running individual # 114000\n",
      "Running individual # 115000\n",
      "Running individual # 116000\n",
      "Running individual # 117000\n",
      "Running individual # 118000\n",
      "Running individual # 119000\n",
      "Running individual # 120000\n",
      "Running individual # 121000\n",
      "Running individual # 122000\n",
      "Running individual # 123000\n",
      "Running individual # 124000\n",
      "Running individual # 125000\n",
      "Running individual # 126000\n",
      "Running individual # 127000\n",
      "Running individual # 128000\n",
      "Running individual # 129000\n",
      "Running individual # 130000\n",
      "Running individual # 131000\n",
      "Running individual # 132000\n",
      "Running individual # 133000\n",
      "Running individual # 134000\n",
      "Running individual # 135000\n",
      "Running individual # 136000\n",
      "Running individual # 137000\n",
      "Running individual # 138000\n",
      "Running individual # 139000\n",
      "Running individual # 140000\n",
      "Running individual # 141000\n",
      "Running individual # 142000\n",
      "Running individual # 143000\n",
      "Running individual # 144000\n",
      "Running individual # 145000\n",
      "Running individual # 146000\n",
      "Running individual # 147000\n",
      "Running individual # 148000\n",
      "Running individual # 149000\n",
      "Running individual # 150000\n",
      "Running individual # 151000\n",
      "Running individual # 152000\n",
      "Running individual # 153000\n",
      "Running individual # 154000\n",
      "Running individual # 155000\n",
      "Running individual # 156000\n",
      "Running individual # 157000\n",
      "Running individual # 158000\n",
      "Running individual # 159000\n",
      "Running individual # 160000\n",
      "Running individual # 161000\n",
      "Running individual # 162000\n",
      "Running individual # 163000\n",
      "Running individual # 164000\n",
      "Running individual # 165000\n",
      "Running individual # 166000\n",
      "Sucessfully written: n=166756 fastas into ./output/singleseq/\n",
      "Paths already existing: n=0\n",
      "Saved Summary Dataframe n=166919 to ./output/single_seq_split.tsv\n",
      "CPU times: user 33min 3s, sys: 44.7 s, total: 33min 47s\n",
      "Wall time: 1h 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#fasta_path = \"./data/apr20/gisaid_hcov-19_2020_04_29_23_mod.fasta\" # End of April Version\n",
    "#fasta_path = \"./data/may20/gisaid_hcov-19_2020_05_09_05.fasta\"\n",
    "fasta_path = \"./data/oct20/sequences_2020-10-30_07-23.fasta\"\n",
    "savepath = \"./output/single_seq_split.tsv\"\n",
    "min_cov_bs = 20000\n",
    "\n",
    "fiter = fasta_iter(fasta_path)\n",
    "iids = np.array([ff[0] for ff in fiter])\n",
    "print(f\"Loaded n={len(iids)} IIDs\")\n",
    "\n",
    "### Could Filter IIDs here\n",
    "print(f\"Splitting up fastas...\")\n",
    "df = split_fasta(fasta_name=fasta_path, \n",
    "            path_out=\"./output/singleseq/\", \n",
    "            iids=iids[:], clean=True, \n",
    "            min_cov_bs=min_cov_bs, output=False)\n",
    "\n",
    "df.to_csv(savepath, sep=\"\\t\", index=False)\n",
    "print(f\"Saved Summary Dataframe n={len(df)} to {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge new Individuals into existing dataframe\n",
    "(only keep the existing ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./output/single_seq_split.tsv\", sep=\"\\t\")  # Containg the results to add\n",
    "df2 = pd.read_csv(\"./output/df_alignment_existing.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Wuhan|IVDC-HB-01|2019\n",
       "1            Wuhan|IVDC-HB-04|2020\n",
       "2            Wuhan|IVDC-HB-05|2019\n",
       "3         Wuhan|IPBCAMS-WH-01|2019\n",
       "4                 Wuhan|WIV04|2019\n",
       "                    ...           \n",
       "166914       Australia|SAP519|2020\n",
       "166915       Australia|SAP520|2020\n",
       "166916       Australia|SAP521|2020\n",
       "166917       Australia|SAP522|2020\n",
       "166918       Australia|SAP516|2020\n",
       "Name: iid, Length: 166919, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"iid\"].str.replace(\"/\", \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 166919 sequences to newly algin\n",
      "Loaded 17159 sequences already aligned\n",
      "combined to  184078 Unique clean IDs\n",
      "Saved New full Dataframe (n=17160) to ./output/single_seq_aligned_temp.tsv\n",
      "CPU times: user 983 ms, sys: 83.4 ms, total: 1.07 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_merge = merge_new_existing_df(path_new = \"./output/single_seq_split.tsv\", # The new sample to include\n",
    "                                 path_existing = \"./output/df_alignment_existing.tsv\",  # Former alignment to load (save there if tests complete)\n",
    "                                 savepath = \"./output/single_seq_aligned_temp.tsv\")  # New alignment to save to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the full alignment\n",
    "Requires mafft in path\n",
    "\n",
    "2) Align 1by1. (takes 20 min per 5000 new seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total alignment rows: 17160\n",
      "Successfully newly aligned n=0 sequences.\n",
      "Saved Summary Dataframe n=17160 to ./output/single_seq_aligned_temp1.tsv\n",
      "CPU times: user 3.18 s, sys: 18.6 ms, total: 3.19 s\n",
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"./output/single_seq_aligned_temp.tsv\", sep=\"\\t\")  # Containg the results to add\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "align_mafft_multiple(df, \n",
    "                     in_folder = \"./output/singleseq/\",\n",
    "                     out_folder=\"./output/singleseq_aligned/\",\n",
    "                     ref_path = \"./data/reference/wuhan-hu-1.fasta\",\n",
    "                     save_path_df = \"./output/single_seq_aligned_temp1.tsv\", # Where to save the full, new output\n",
    "                     overwrite=False, output=False,\n",
    "                     threads=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If all successful: Overwrite the exisiting \"backup\"\n",
    "Only do that if everything works - there is no way back!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17159 Individuals\n",
      "Saved to ./output/df_alignment_existing.tsv\n"
     ]
    }
   ],
   "source": [
    "loadpath = \"./output/single_seq_aligned_temp1.tsv\"\n",
    "savepath = \"./output/df_alignment_existing.tsv\"\n",
    "\n",
    "df = pd.read_csv(loadpath, sep=\"\\t\") \n",
    "print(f\"Loaded {len(df)} Individuals\")\n",
    "df.to_csv(savepath, sep=\"\\t\", index=False)\n",
    "print(f\"Saved to {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51\n",
    "Test code chunks here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./output/single_seq_aligned2.tsv\", sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run single test alignment\n",
    "(requires MAFFT in path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.67 ms, sys: 11.8 ms, total: 19.5 ms\n",
      "Wall time: 353 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "in_path = \"./output/singleseq/hCoV-19.Beijing.235.2020.EPI_ISL_413521.2020-01-28.fasta\"\n",
    "out_path = \"./output/singleseq_aligned/test_out1.fasta\"\n",
    "\n",
    "align_mafft(in_path=in_path, out_path=out_path, thread=10, output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fasta = in_path\n",
    "\n",
    "fiter = fasta_iter(path_fasta)\n",
    "iids = np.array([ff[0] for ff in fiter])\n",
    "fiter = fasta_iter(path_fasta)\n",
    "seqs = np.array([ff[1] for ff in fiter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29622"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fasta = out_path\n",
    "\n",
    "fiter = fasta_iter(path_fasta)\n",
    "iids = np.array([ff[0] for ff in fiter])\n",
    "fiter = fasta_iter(path_fasta)\n",
    "seqs = np.array([ff[1] for ff in fiter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29903"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load multi fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fasta = \"./data/mar20/gisaid_cov2020_sequences_30.fasta\"\n",
    "fiter = fasta_iter(path_fasta)\n",
    "iids = np.array([ff[0] for ff in fiter])\n",
    "fiter = fasta_iter(path_fasta)  # iter_raw\n",
    "seqs = np.array([ff[1] for ff in fiter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_iid = 'hCoV-19/Scotland/EDB007/2020|EPI_ISL_415634|2020-03-06'\n",
    "target_iid = 'hCoV-19/USA/WA-S91/2020|EPI_ISL_417144|2020-03-02'\n",
    "idx = (iids==target_iid)\n",
    "#idx = (iids==\"hCoV-19/Japan/DP0763/2020|EPI_ISL_416623|2020-02-17\")\n",
    "np.sum(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29903\n"
     ]
    }
   ],
   "source": [
    "seq = seqs[idx][0]\n",
    "print(len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(22900,23101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load single fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fasta = \"./output/singleseq/hCoV-19.Australia.NSW01.2020.EPI_ISL_407893.2020-01-24.fasta\"\n",
    "fiter = fasta_iter_raw(path_fasta)\n",
    "iid, seq = next(fiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Coverage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiter = fasta_iter_raw(\"./data/mar20/gisaid_cov2020_sequences_30.fasta\")\n",
    "seqs = np.array([ff[1] for ff in fiter])\n",
    "covered = [len(s) - s.count('\\n') - s.count(\"N\") for s in seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(0, 31000, 100)\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.hist(covered, bins=bins, ec=\"k\")\n",
    "ax.set_xlim([20000,31000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AB___Cd_E'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"AB   Cd E\"\n",
    "test1 = re.sub(\"\\s\", \"_\", test)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>iid_clean</th>\n",
       "      <th>cov</th>\n",
       "      <th>include</th>\n",
       "      <th>aligned_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hCoV-19/USA/WA-S88/2020|EPI_ISL_417141|2020-03-01</td>\n",
       "      <td>hCoV-19.USA.WA-S88.2020.EPI_ISL_417141.2020-03-01</td>\n",
       "      <td>29868</td>\n",
       "      <td>True</td>\n",
       "      <td>./output/singleseq_aligned/hCoV-19.USA.WA-S88....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hCoV-19/USA/WA-S89/2020|EPI_ISL_417142|2020-02-29</td>\n",
       "      <td>hCoV-19.USA.WA-S89.2020.EPI_ISL_417142.2020-02-29</td>\n",
       "      <td>29858</td>\n",
       "      <td>True</td>\n",
       "      <td>./output/singleseq_aligned/hCoV-19.USA.WA-S89....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hCoV-19/USA/WA-S87/2020|EPI_ISL_417140|2020-03-01</td>\n",
       "      <td>hCoV-19.USA.WA-S87.2020.EPI_ISL_417140.2020-03-01</td>\n",
       "      <td>29869</td>\n",
       "      <td>True</td>\n",
       "      <td>./output/singleseq_aligned/hCoV-19.USA.WA-S87....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hCoV-19/USA/WA-S92/2020|EPI_ISL_417145|2020-02-29</td>\n",
       "      <td>hCoV-19.USA.WA-S92.2020.EPI_ISL_417145.2020-02-29</td>\n",
       "      <td>29868</td>\n",
       "      <td>True</td>\n",
       "      <td>./output/singleseq_aligned/hCoV-19.USA.WA-S92....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hCoV-19/USA/WA-S93/2020|EPI_ISL_417146|2020-02-29</td>\n",
       "      <td>hCoV-19.USA.WA-S93.2020.EPI_ISL_417146.2020-02-29</td>\n",
       "      <td>29868</td>\n",
       "      <td>True</td>\n",
       "      <td>./output/singleseq_aligned/hCoV-19.USA.WA-S93....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17155</th>\n",
       "      <td>hCoV-19/USA/FL-BPHL-046/2020|EPI_ISL_436550|20...</td>\n",
       "      <td>hCoV-19.USA.FL-BPHL-046.2020.EPI_ISL_436550.20...</td>\n",
       "      <td>29204</td>\n",
       "      <td>True</td>\n",
       "      <td>./output/singleseq_aligned/hCoV-19.USA.FL-BPHL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17156</th>\n",
       "      <td>hCoV-19/USA/FL-BPHL-047/2020|EPI_ISL_436551|20...</td>\n",
       "      <td>hCoV-19.USA.FL-BPHL-047.2020.EPI_ISL_436551.20...</td>\n",
       "      <td>28632</td>\n",
       "      <td>True</td>\n",
       "      <td>./output/singleseq_aligned/hCoV-19.USA.FL-BPHL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17157</th>\n",
       "      <td>hCoV-19/USA/FL-BPHL-048/2020|EPI_ISL_436552|20...</td>\n",
       "      <td>hCoV-19.USA.FL-BPHL-048.2020.EPI_ISL_436552.20...</td>\n",
       "      <td>29084</td>\n",
       "      <td>True</td>\n",
       "      <td>./output/singleseq_aligned/hCoV-19.USA.FL-BPHL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17158</th>\n",
       "      <td>hCoV-19/USA/FL-BPHL-051/2020|EPI_ISL_436555|20...</td>\n",
       "      <td>hCoV-19.USA.FL-BPHL-051.2020.EPI_ISL_436555.20...</td>\n",
       "      <td>28771</td>\n",
       "      <td>True</td>\n",
       "      <td>./output/singleseq_aligned/hCoV-19.USA.FL-BPHL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17159</th>\n",
       "      <td>Wuhan/IVDC-HB-01/2019</td>\n",
       "      <td>Wuhan.IVDC-HB-01.2019</td>\n",
       "      <td>29891</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17160 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     iid  \\\n",
       "0      hCoV-19/USA/WA-S88/2020|EPI_ISL_417141|2020-03-01   \n",
       "1      hCoV-19/USA/WA-S89/2020|EPI_ISL_417142|2020-02-29   \n",
       "2      hCoV-19/USA/WA-S87/2020|EPI_ISL_417140|2020-03-01   \n",
       "3      hCoV-19/USA/WA-S92/2020|EPI_ISL_417145|2020-02-29   \n",
       "4      hCoV-19/USA/WA-S93/2020|EPI_ISL_417146|2020-02-29   \n",
       "...                                                  ...   \n",
       "17155  hCoV-19/USA/FL-BPHL-046/2020|EPI_ISL_436550|20...   \n",
       "17156  hCoV-19/USA/FL-BPHL-047/2020|EPI_ISL_436551|20...   \n",
       "17157  hCoV-19/USA/FL-BPHL-048/2020|EPI_ISL_436552|20...   \n",
       "17158  hCoV-19/USA/FL-BPHL-051/2020|EPI_ISL_436555|20...   \n",
       "17159                              Wuhan/IVDC-HB-01/2019   \n",
       "\n",
       "                                               iid_clean    cov  include  \\\n",
       "0      hCoV-19.USA.WA-S88.2020.EPI_ISL_417141.2020-03-01  29868     True   \n",
       "1      hCoV-19.USA.WA-S89.2020.EPI_ISL_417142.2020-02-29  29858     True   \n",
       "2      hCoV-19.USA.WA-S87.2020.EPI_ISL_417140.2020-03-01  29869     True   \n",
       "3      hCoV-19.USA.WA-S92.2020.EPI_ISL_417145.2020-02-29  29868     True   \n",
       "4      hCoV-19.USA.WA-S93.2020.EPI_ISL_417146.2020-02-29  29868     True   \n",
       "...                                                  ...    ...      ...   \n",
       "17155  hCoV-19.USA.FL-BPHL-046.2020.EPI_ISL_436550.20...  29204     True   \n",
       "17156  hCoV-19.USA.FL-BPHL-047.2020.EPI_ISL_436551.20...  28632     True   \n",
       "17157  hCoV-19.USA.FL-BPHL-048.2020.EPI_ISL_436552.20...  29084     True   \n",
       "17158  hCoV-19.USA.FL-BPHL-051.2020.EPI_ISL_436555.20...  28771     True   \n",
       "17159                              Wuhan.IVDC-HB-01.2019  29891     True   \n",
       "\n",
       "                                            aligned_path  \n",
       "0      ./output/singleseq_aligned/hCoV-19.USA.WA-S88....  \n",
       "1      ./output/singleseq_aligned/hCoV-19.USA.WA-S89....  \n",
       "2      ./output/singleseq_aligned/hCoV-19.USA.WA-S87....  \n",
       "3      ./output/singleseq_aligned/hCoV-19.USA.WA-S92....  \n",
       "4      ./output/singleseq_aligned/hCoV-19.USA.WA-S93....  \n",
       "...                                                  ...  \n",
       "17155  ./output/singleseq_aligned/hCoV-19.USA.FL-BPHL...  \n",
       "17156  ./output/singleseq_aligned/hCoV-19.USA.FL-BPHL...  \n",
       "17157  ./output/singleseq_aligned/hCoV-19.USA.FL-BPHL...  \n",
       "17158  ./output/singleseq_aligned/hCoV-19.USA.FL-BPHL...  \n",
       "17159                                                     \n",
       "\n",
       "[17160 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge[\"iid\"].str.split(\"|\").str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
