{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directly create h5 from aligned next fasta.\n",
    "Also has functions to process to variant fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current machine: compute-a-16-106.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/covid19_data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n",
    "from shutil import which\n",
    "import os\n",
    "import re as re\n",
    "import h5py\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "socket_name = socket.gethostname()\n",
    "print(f\"Current machine: {socket_name}\")\n",
    "if socket_name == \"DESKTOP-5RJD9NC\":\n",
    "    path = \"/gitProjects/covid19_data\"   # The Path on Harald's machine\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/covid19_data/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "### Check whether required bins are available\n",
    "req_bins = [\"mafft\"] \n",
    "for b in req_bins:\n",
    "    s = which(b)\n",
    "    if not s:\n",
    "        print(f\"Make sure to install {b} and have in path. I cannot find it!\")\n",
    "        \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd())\n",
    "\n",
    "sys.path.append(\"./python3/\")\n",
    "from manipulate_fasta import fasta_iter_raw, fasta_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_h5(seqs, iids, path, output=True):\n",
    "        \"\"\"Create a new HDF5 File with Sequence Data.\n",
    "        Each sequence entry is saved as a single char.\n",
    "        seqs: Genomic Data: [k,l] array\n",
    "        iids: IIDs to save into HDF5.\n",
    "        path: Where to save the HDF5 to\"\"\"\n",
    "        k, l = np.shape(seqs)  # Nr of Individuals and Nr of Loci\n",
    "        assert(k == len(iids)) ## Sanity Chec\n",
    "        \n",
    "        max_len = np.max([len(iid) for iid in iids]) # Longest iid\n",
    "\n",
    "        if os.path.exists(path):  # Do a Deletion of existing File there\n",
    "            os.remove(path)\n",
    "            \n",
    "        dt = h5py.special_dtype(vlen=str)  # To have no problem with saving\n",
    "\n",
    "        with h5py.File(path, 'w') as f0:\n",
    "            ### Create all the Groups\n",
    "            f_gt = f0.create_dataset(\"gt\", (k,l), dtype='|S1')\n",
    "            f_samples = f0.create_dataset(\"samples\", (k,), dtype=dt)\n",
    "\n",
    "            ### Save the Data\n",
    "            f_gt[:] = seqs.astype(\"|S1\")\n",
    "            f_samples[:] = np.array(iids)   #.astype(\"S\" + max_len)\n",
    "\n",
    "        if output == True:\n",
    "            print(f\"Successfully saved {k} individuals to: {path}\")\n",
    "            \n",
    "def get_iids_seqs_from_aligned_fasta(path_fasta=\"./data/oct20/sequences_2020-10-30_07-23.fasta\"):\n",
    "    \"\"\"Get IIDs and Sequences from aligned Fasta file.\"\"\"\n",
    "\n",
    "    fiter = fasta_iter(path_fasta)\n",
    "    print(\"Getting IIDs...\")\n",
    "    iids = np.array([ff[0] for ff in fiter])\n",
    "\n",
    "    fiter = fasta_iter(path_fasta)\n",
    "    s = next(fiter)[1]\n",
    "\n",
    "    seqs = np.empty((len(iids),len(s)), dtype=\"|S1\")\n",
    "    fiter = fasta_iter(path_fasta)\n",
    "    for i in range(len(iids)):\n",
    "        if i%10000==0:\n",
    "            print(f\"Running sequence {i}\")\n",
    "        s = next(fiter)[1]\n",
    "        seqs[i,:]=list(s)\n",
    "    return iids, seqs\n",
    "\n",
    "def post_process_counts(ct, drop=[b\"n\", b\"-\"]):\n",
    "    \"\"\"Post-process Pandas value Counts.\n",
    "    drop: What allele to drop and not to count\"\"\"\n",
    "    ct = ct.drop(labels = drop, errors=\"ignore\")\n",
    "    if len(ct)==1:\n",
    "        gt_ct = [ct.values[0], 0]\n",
    "        alleles = [ct.index[0], \"\"]\n",
    "    else:\n",
    "        gt_ct = [ct.values[0], ct.values[1]]\n",
    "        alleles = [ct.index[0], ct.index[1]]\n",
    "    return gt_ct, alleles\n",
    "\n",
    "def produce_allele_stats(seq, drop=[b\"n\", b\"-\"], loci=[],\n",
    "                         decode=True):\n",
    "    \"\"\"Produce allele counts for major/minor allele\n",
    "    loci: Which Loci to analyze\n",
    "    decode: Whether to decode S1 strings in output\"\"\"\n",
    "    counts = []\n",
    "    \n",
    "    if len(loci)==0:\n",
    "        k = np.shape(seqs)[1]\n",
    "        loci = range(0,k)\n",
    "        print(f\"Running all Loci: n={len(loci)}\")\n",
    "        \n",
    "    ref_count, alt_count = np.zeros(len(loci), dtype=\"int\"), np.zeros(len(loci), dtype=\"int\")\n",
    "    ref, alt  =  np.empty(len(loci), dtype=\"|S1\"), np.empty(len(loci), dtype=\"|S1\")\n",
    "    \n",
    "    for i,l in enumerate(loci):\n",
    "        ct = pd.value_counts(seqs[:,l])\n",
    "        gts_c, alleles = post_process_counts(ct, drop=drop)\n",
    "        ref_count[i], alt_count[i] = gts_c\n",
    "        ref[i], alt[i] = alleles\n",
    "    \n",
    "    df = pd.DataFrame({\"refcount\":ref_count, \"altcount\":alt_count, \n",
    "                  \"ref\":ref, \"alt\":alt, \"pos\":loci})\n",
    "    if decode:\n",
    "        df['ref'] = df['ref'].str.decode(\"utf-8\")\n",
    "        df['alt'] = df['alt'].str.decode(\"utf-8\")\n",
    "    return df\n",
    "\n",
    "def extract_var_df(df, frac_tot=0.75, maf=0.05):\n",
    "    \"\"\"Extract and return Dataframe with MAF > maf.\n",
    "    frac_tot: Minimum total individuals with coverage thre\"\"\"\n",
    "    tot_count = df1[\"altcount\"] + df1[\"refcount\"]\n",
    "    count_good =  tot_count>(frac_tot*np.max(tot_count))\n",
    "    print(f\"Minimum Count per Locus required: {frac_tot*np.max(tot_count)}\")\n",
    "    idx = (df1[\"altcount\"] / tot_count > maf) & count_good\n",
    "\n",
    "    print(f\"Found {np.sum(idx)} Variants with MAF>{maf}\")\n",
    "    df_var = df1[idx].copy()\n",
    "\n",
    "    df_var[\"totcount\"] = df_var[\"refcount\"] + df_var[\"altcount\"]\n",
    "    df_var[\"maf\"] = df_var[\"altcount\"]/df_var[\"totcount\"]\n",
    "    return df_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get IIDs and Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting IIDs...\n",
      "Running sequence 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 29896 to array axis with dimension 29891",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-612ac3af0268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_iids_seqs_from_aligned_fasta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_fasta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./data/oct20/sequences_2020-10-30_07-23.fasta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-2f8311003f6a>\u001b[0m in \u001b[0;36mget_iids_seqs_from_aligned_fasta\u001b[0;34m(path_fasta)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running sequence {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mseqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0miids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 29896 to array axis with dimension 29891"
     ]
    }
   ],
   "source": [
    "iids, seqs = get_iids_seqs_from_aligned_fasta(path_fasta=\"./data/oct20/sequences_2020-10-30_07-23.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save them to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 166919 individuals to: ./output/h5/covid_seqs_next.h5\n",
      "CPU times: user 2.44 s, sys: 7.75 s, total: 10.2 s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "save_h5(seqs, iids, path=\"./output/h5/covid_seqs_next.h5\")\n",
    "#seqs = np.array([ff[1] for ff in fiter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Allele Frequency Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'G'    29891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = pd.value_counts(seqs[1008,:])\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 427 ms, sys: 15.8 ms, total: 443 ms\n",
      "Wall time: 440 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df1 = produce_allele_stats(seqs, loci=range(23400,23410), drop=[b\"-\", b\"n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>refcount</th>\n",
       "      <th>altcount</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>23400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>23401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>23402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>23403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>23404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>23405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>23406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>23407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>23408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>23409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   refcount  altcount ref alt    pos\n",
       "0    124638     18226   A   C  23400\n",
       "1    124638     18226   A   C  23401\n",
       "2    124638     18226   A   C  23402\n",
       "3    124638     18226   A   C  23403\n",
       "4    124638     18226   A   C  23404\n",
       "5    124638     18226   A   C  23405\n",
       "6    124638     18226   A   C  23406\n",
       "7    124638     18226   A   C  23407\n",
       "8    124638     18226   A   C  23408\n",
       "9    124638     18226   A   C  23409"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 29891 Loci Statistics to ./output/tables/allele_spectrum_next.tsv\n"
     ]
    }
   ],
   "source": [
    "savepath = \"./output/tables/allele_spectrum_next.tsv\"\n",
    "df1.to_csv(savepath, sep=\"\\t\", index=False)\n",
    "print(f\"Saved {len(df1)} Loci Statistics to {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the table of Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 29891 Loci Statistics from ./output/tables/allele_spectrum_next.tsv\n",
      "Max Ref Count: 124638\n",
      "CPU times: user 19.6 ms, sys: 9.97 ms, total: 29.5 ms\n",
      "Wall time: 31.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "savepath = \"./output/tables/allele_spectrum_next.tsv\"\n",
    "df1 = pd.read_csv(savepath, sep=\"\\t\")\n",
    "print(f\"Loaded {len(df1)} Loci Statistics from {savepath}\")\n",
    "mx_ref = np.max(df1[\"refcount\"])\n",
    "print(f\"Max Ref Count: {mx_ref}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Count per Locus required: 57145.600000000006\n",
      "Found 29891 Variants with MAF>0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "A>C    29891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Showcase what variants we have\n",
    "df_var = extract_var_df(df1, maf = 0.01, frac_tot = 0.4)\n",
    "\n",
    "### Which Mutations\n",
    "mutations = df_var[\"ref\"] + \">\" + df_var[\"alt\"]\n",
    "mutations.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>refcount</th>\n",
       "      <th>altcount</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29886</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>29886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29887</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>29887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29888</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>29888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29889</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>29889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29890</th>\n",
       "      <td>124638</td>\n",
       "      <td>18226</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>29890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29891 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       refcount  altcount ref alt    pos\n",
       "0        124638     18226   A   C      0\n",
       "1        124638     18226   A   C      1\n",
       "2        124638     18226   A   C      2\n",
       "3        124638     18226   A   C      3\n",
       "4        124638     18226   A   C      4\n",
       "...         ...       ...  ..  ..    ...\n",
       "29886    124638     18226   A   C  29886\n",
       "29887    124638     18226   A   C  29887\n",
       "29888    124638     18226   A   C  29888\n",
       "29889    124638     18226   A   C  29889\n",
       "29890    124638     18226   A   C  29890\n",
       "\n",
       "[29891 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fasta = \"./data/oct20/sequences_2020-10-30_07-23.fasta\"\n",
    "fiter = fasta_iter(path_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(fiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = np.array([len(s) for s in seqs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test filling empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = np.empty((3,2), dtype=\"|S1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 3 to array axis with dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-937c0f3bf5d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"abc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 3 to array axis with dimension 2"
     ]
    }
   ],
   "source": [
    "seqs[1,:]=list(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'\\xc8', b'7'],\n",
       "       [b'a', b'b'],\n",
       "       [b'\\xd9', b'\\x7f']], dtype='|S1')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
